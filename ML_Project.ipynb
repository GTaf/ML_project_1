{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_helpers\n",
    "import implementations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting dataset\")\n",
    "y_train_ref_source, X_train_ref_source, id1 = proj1_helpers.load_csv_data(\"train.csv\")\n",
    "#y_test_ref, X_test_ref, id2 = proj1_helpers.load_csv_data(\"test.csv\")\n",
    "\n",
    "X_train_ref, X_test_ref, y_train_ref, y_test_ref = implementations.split_data(X_train_ref_source, y_train_ref_source, 0.99,23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247500, 120)\n",
      "number of features :  120\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([X_train_ref,np.power(X_train_ref,2),np.power(X_train_ref,3),np.power(X_train_ref,4)],axis = 1)\n",
    "y_train = y_train_ref\n",
    "X_test = np.concatenate((X_test_ref,np.power(X_test_ref,2),np.power(X_test_ref,3),np.power(X_test_ref,4)),axis = 1)\n",
    "y_test = y_test_ref\n",
    "print(X_train.shape)\n",
    "\n",
    "num_features = X_train[0].shape[0]\n",
    "print(\"number of features : \", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(lambda_, degree, batch_size):\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(1,degree+1):\n",
    "        x.append(np.power(X_train_ref,i))\n",
    "        xt.append(np.power(X_test_ref,i))\n",
    "        \n",
    "    X_train = np.concatenate(x,axis = 1)\n",
    "    y_train = y_train_ref\n",
    "    X_test = np.concatenate(xt,axis = 1)\n",
    "    y_test = y_test_ref\n",
    "    \n",
    "    #print(\"X_train shape : \", X_train.shape,\"    X_test.shape : \", X_test.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape,\"    y_test.shape : \", y_test.shape)\n",
    "    \n",
    "    num_features = X_train[0].shape[0]\n",
    "    #print(\"number of features : \", num_features)\n",
    "\n",
    "    #print(\"Splitting dataset into batch\")\n",
    "    X_batch = np.array_split(X_train, 1)\n",
    "    y_batch = np.array_split(y_train, 1)\n",
    "\n",
    "    #print(X_batch[0].shape)\n",
    "    \n",
    "    w = []\n",
    "    i=0\n",
    "    for y,batch in zip(y_batch,X_batch):\n",
    "        w.append(implementations.ridge_regression(y, batch,lambda_))\n",
    "    \n",
    "    \n",
    "    wp = w[0]# np.sum(np.array(w),axis=0)/(len(X_batch))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    y_pred_ridge_train = proj1_helpers.predict_labels(wp,X_train)\n",
    "    y_pred_ridge_test = proj1_helpers.predict_labels(wp,X_test)\n",
    "    s_tr = 0\n",
    "    s_te = 0\n",
    "    tot_tr = 0\n",
    "    for i,y in enumerate(y_train):\n",
    "        if y == y_pred_ridge_train[i]:\n",
    "            s_tr += 1\n",
    "        tot_tr += 1\n",
    "    tot_te = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y == y_pred_ridge_test[i]:\n",
    "            s_te += 1\n",
    "        tot_te += 1\n",
    "\n",
    "    print(\"Ridge precision on train : \",s_tr/tot_tr,\"     Ridge precision on test : \",s_te/tot_te)\n",
    "    \n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge precision on train :  0.7998060606060606      Ridge precision on test :  0.7936\n",
      "Ridge precision on train :  0.7998060606060606      Ridge precision on test :  0.7936\n",
      "Ridge precision on train :  0.7998060606060606      Ridge precision on test :  0.7936\n",
      "Ridge precision on train :  0.7998060606060606      Ridge precision on test :  0.7936\n",
      "Ridge precision on train :  0.7998060606060606      Ridge precision on test :  0.7936\n",
      "Ridge precision on train :  0.7998060606060606      Ridge precision on test :  0.7936\n"
     ]
    }
   ],
   "source": [
    "w = batch(100,6,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.88974478e-02   3.97616379e-03   6.95056564e-03  -3.65114751e-03\n",
      "  -1.05635577e-01  -3.39685598e-03  -6.25414924e-02  -1.58937752e-01\n",
      "  -8.07534279e-04   1.55052512e-02  -9.35542438e-02  -1.33669130e-01\n",
      "   3.62772072e-01   3.45453955e-02  -5.84327079e-04   9.09695424e-04\n",
      "  -4.74437973e-04   1.13392038e-03   7.00690231e-03  -7.95160673e-03\n",
      "   6.70521106e-04   2.85491152e-03  -2.91127359e-02   1.72375800e-02\n",
      "   1.40592332e-03   4.47730768e-03   1.30371744e-02   1.74732716e-02\n",
      "   4.11183749e-03  -1.81215731e-02  -1.35851573e-04  -3.14824882e-04\n",
      "  -1.37480561e-04   4.48096655e-05   1.61766239e-02   6.53288198e-06\n",
      "  -1.37841520e-03   7.54775977e-02  -1.95137007e-05   2.84272402e-05\n",
      "   1.02272302e-01   1.24187892e-02  -3.90335277e-02  -6.58096252e-04\n",
      "  -5.65537330e-04   3.92146012e-04  -3.99696792e-04  -3.43216538e-02\n",
      "   2.04614123e-03   2.19077950e-04  -1.38744971e-03  -1.15048370e-05\n",
      "  -5.34865126e-02  -1.77162168e-04   4.02430635e-02   5.21002305e-04\n",
      "  -7.80763384e-05   3.64150077e-02   7.52431736e-04  -2.83960364e-05\n",
      "   1.95630607e-07   3.18632010e-06   6.29088984e-07  -2.84559929e-07\n",
      "   6.66299817e-04  -5.79552163e-09   3.63948912e-04   1.52301442e-01\n",
      "   6.06858645e-07  -6.14855719e-08  -2.11952759e-02   2.30829588e-01\n",
      "   9.74857342e-04   3.69189004e-06  -4.71474523e-04   2.94055972e-04\n",
      "   3.42169878e-06  -2.50803232e-04  -9.65710829e-04  -1.74190918e-06\n",
      "   5.87492516e-04   1.41893332e-08  -9.28003406e-02   9.44713953e-07\n",
      "  -2.24451880e-04  -4.96140626e-04   1.75355004e-07  -1.83168600e-03\n",
      "  -5.82299677e-04   7.68916738e-08   1.99898242e-11  -1.20998240e-08\n",
      "  -1.16370098e-09   8.24448008e-10  -1.37433556e-06   2.48786917e-12\n",
      "  -5.46482739e-06  -1.04880867e-01  -3.60152093e-09   7.26802162e-11\n",
      "   1.83768545e-03   1.52171230e-02   5.56312703e-06  -1.01250930e-08\n",
      "  -9.18900760e-03  -4.78473447e-04  -1.41106679e-08  -1.59143783e-03\n",
      "  -6.39791864e-04   6.16786363e-09   8.67681780e-04  -4.90321502e-12\n",
      "  -1.43040332e-01  -2.58373083e-09  -3.17922576e-06   2.94055577e-06\n",
      "   7.51477235e-11  -1.16241628e-06   2.38153380e-06  -1.11732228e-10\n",
      "  -2.25795154e-13   1.93924135e-11   9.29391007e-13  -1.09954576e-12\n",
      "   5.45659722e-09  -5.00223304e-16  -7.63183935e-10   2.35564801e-02\n",
      "   7.66129585e-12  -4.13889023e-14  -7.15096010e-05  -6.92067342e-02\n",
      "   9.43043111e-10   1.27961214e-11   7.27539500e-05  -4.51300861e-05\n",
      "   2.73979696e-11  -8.74889721e-05   2.22256927e-06  -9.72251087e-12\n",
      "  -7.76960956e-05  -1.66369998e-15  -1.58123497e-01   3.41874806e-12\n",
      "   1.25753209e-09  -8.57126115e-10  -7.89503742e-13  -6.85198685e-09\n",
      "   1.61312717e-09   7.73947694e-14   1.17133021e-16  -1.10565444e-14\n",
      "  -2.66524863e-16   5.42989464e-16   6.42099811e-13   3.75721734e-20\n",
      "   8.82435461e-13  -1.73938005e-03  -5.38093015e-15   8.87908010e-18\n",
      "   1.03610705e-06  -5.25559620e-03  -1.69333202e-13  -5.87882767e-15\n",
      "   1.02789051e-03   5.20069574e-05  -2.01489919e-14   3.50447320e-04\n",
      "   5.14575296e-05   5.53830342e-15  -8.29115749e-05   7.92160455e-19\n",
      "   6.70268239e-02  -1.72199640e-15   4.11359063e-12  -4.22843999e-12\n",
      "   7.25316953e-16  -3.25256877e-12   1.92817249e-12  -1.95176467e-17]\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD precision on train :  0.77\n",
      "GD precision on test :  0.266080070391553\n"
     ]
    }
   ],
   "source": [
    "y_pred_GD_train = proj1_helpers.predict_labels(wg,X_train)\n",
    "s = 0\n",
    "tot = 0\n",
    "for i,y in enumerate(y_pred_ridge_train):\n",
    "    if y == y_train[i]:\n",
    "        s += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"GD precision on train : \",s/tot)\n",
    "\n",
    "y_pred_GD_test = proj1_helpers.predict_labels(wg,X_test)\n",
    "s = 0\n",
    "tot = 0\n",
    "for i,y in enumerate(y_pred_ridge_test):\n",
    "    if y == y_test[i]:\n",
    "        s += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"GD precision on test : \",s/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest, input_data_test, ids_test = proj1_helpers.load_csv_data(\"test.csv\")\n",
    "xsub = []\n",
    "degree = 6\n",
    "for i in range(1,degree+1):\n",
    "    xsub.append(np.power(input_data_test,i))\n",
    "        \n",
    "inp = np.concatenate(xsub,axis = 1)\n",
    "ypred = proj1_helpers.predict_labels(w, inp)\n",
    "proj1_helpers.create_csv_submission(ids_test, ypred, \"pred1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
