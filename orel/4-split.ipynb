{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "import proj1_helpers\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(\"../train.csv\",sub_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultimate_split(yb, input_data, ids):\n",
    "    \"\"\"\n",
    "    The ultimate split. THE real BADA$$.\n",
    "    This is some real shit\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_0 = (input_data[:,22] == 0)\n",
    "    mask_1 = (input_data[:,22] == 1)\n",
    "    mask_2 = (input_data[:,22] == 2)\n",
    "    mask_3 = (input_data[:,22] == 3)\n",
    "\n",
    "    \n",
    "    return [[yb[mask_0], input_data[mask_0], ids[mask_0]], [yb[mask_1], input_data[mask_1], ids[mask_1]],\n",
    "           [yb[mask_2], input_data[mask_2], ids[mask_2]],[yb[mask_3], input_data[mask_3], ids[mask_3]]]\n",
    "\n",
    "def remove_features_0(input_data_0):\n",
    "    \"\"\"\n",
    "    Remove the useless features if the jet num feature is equal to 0\n",
    "    \"\"\"\n",
    "    useless_features_index = [4, 5, 6, 12, 23, 24, 25 , 26, 27, 28]#, 30, 33]\n",
    "    \n",
    "    mask = np.ones(int(input_data_0.shape[1]), dtype=bool)\n",
    "    mask[(useless_features_index)] = False\n",
    "    return input_data_0[:,mask]\n",
    "\n",
    "def remove_features_1(input_data_1):\n",
    "    \"\"\"\n",
    "    Remove the useless features if the jet num feature is equal to 1\n",
    "    \"\"\"\n",
    "    useless_features_index = [4, 5, 6, 12, 26, 27, 28]#, 30, 33]\n",
    "    \n",
    "    mask = np.ones(int(input_data_1.shape[1]), dtype=bool)\n",
    "    mask[(useless_features_index)] = False\n",
    "    return input_data_1[:,mask]\n",
    "\n",
    "    # No need for jet_num equal to 2 or 3 : all the features are kept\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x)\n",
    "    x = x / std_x\n",
    "    return x\n",
    "def split_1st_coordinate(y,x,id):\n",
    "    y1,y2,x1,x2,id1,id2 = [],[],[],[],[],[]\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if x[i][0] == -999:\n",
    "            y1.append(y[i])\n",
    "            x1.append(standardize(x[i][1:]))\n",
    "            id1.append(id[i])\n",
    "        else:\n",
    "            y2.append(y[i])\n",
    "            x2.append(standardize(x[i]))\n",
    "            id2.append(id[i])\n",
    "            \n",
    "    return [[y1, np.array(x1), id1], \n",
    "                     [y2, np.array(x2), id2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D contains all the datat structures, to acess data you should use D[num_jet_case*2 + value of first column is != -999] = y,x,id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splitted = ultimate_split(yb, input_data, ids)\n",
    "data_splitted[0][1] = remove_features_0(data_splitted[0][1])\n",
    "data_splitted[1][1] = remove_features_1(data_splitted[1][1])\n",
    "\n",
    "D = []\n",
    "\n",
    "for d in data_splitted:\n",
    "    s = split_1st_coordinate(d[0],d[1],d[2])\n",
    "    D.append(s[0])\n",
    "    D.append(s[1])\n",
    "D = np.array(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_ridge_in(lambda_, degree, batch_size,d,y):\n",
    "    print(d.shape,y.shape)\n",
    "    d_train, d_test, y_train, y_test = split_data(d,y,0.9,23)\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(1,degree+1):\n",
    "        x.append(np.power(d_train,i))\n",
    "        xt.append(np.power(d_test,i))\n",
    "        \n",
    "    X_train = np.concatenate(x,axis = 1)\n",
    "    #y_train = y_in_train_ref\n",
    "    X_test = np.concatenate(xt,axis = 1)\n",
    "    #y_test = y_in_test_ref\n",
    "    \n",
    "    #print(\"X_train shape : \", X_train.shape,\"    X_test.shape : \", X_test.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape,\"    y_test.shape : \", y_test.shape)\n",
    "    \n",
    "    num_features = X_train[0].shape[0]\n",
    "    #print(\"number of features : \", num_features)\n",
    "\n",
    "    #print(\"Splitting dataset into batch\")\n",
    "    X_batch = np.array_split(X_train, 1)\n",
    "    y_batch = np.array_split(y_train, 1)\n",
    "\n",
    "    #print(X_batch[0].shape)\n",
    "    \n",
    "    w = []\n",
    "    i=0\n",
    "    for y,batch in zip(y_batch,X_batch):\n",
    "        w.append(ridge_regression(y, batch,lambda_))\n",
    "    \n",
    "    \n",
    "    wp =  np.sum(np.array(w),axis=0)/(len(X_batch))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    y_pred_ridge_train = proj1_helpers.predict_labels(wp,X_train)\n",
    "    y_pred_ridge_test = proj1_helpers.predict_labels(wp,X_test)\n",
    "    s_tr = 0\n",
    "    s_te = 0\n",
    "    tot_tr = 0\n",
    "    for i,y in enumerate(y_train):\n",
    "        if y == y_pred_ridge_train[i]:\n",
    "            s_tr += 1\n",
    "        tot_tr += 1\n",
    "    tot_te = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y == y_pred_ridge_test[i]:\n",
    "            s_te += 1\n",
    "        tot_te += 1\n",
    "\n",
    "    print(\"Ridge precision on train : \",s_tr/tot_tr,\"     Ridge precision on test : \",s_te/tot_te)\n",
    "    \n",
    "    return wp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26123, 19) (26123,)\n",
      "Ridge precision on train :  0.9407060825180774      Ridge precision on test :  0.939150401836969\n",
      "(73790, 20) (73790,)\n",
      "Ridge precision on train :  0.7764978693288762      Ridge precision on test :  0.782355332700908\n",
      "(7562, 22) (7562,)\n",
      "Ridge precision on train :  0.912417340191036      Ridge precision on test :  0.9141347424042272\n",
      "(69982, 23) (69982,)\n",
      "Ridge precision on train :  0.6996173570646047      Ridge precision on test :  0.7041005857979712\n",
      "(2952, 29) (2952,)\n",
      "Ridge precision on train :  0.8919427710843374      Ridge precision on test :  0.918918918918919\n",
      "(47427, 30) (47427,)\n",
      "Ridge precision on train :  0.746860650360791      Ridge precision on test :  0.7389837655492304\n",
      "(1477, 29) (1477,)\n",
      "Ridge precision on train :  0.9307750188111362      Ridge precision on test :  0.918918918918919\n",
      "(20687, 30) (20687,)\n",
      "Ridge precision on train :  0.7398216779460737      Ridge precision on test :  0.7472208796520058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for seti in range(8):\n",
    "    batch_ridge_in(10,3,1,np.array(D[seti][1]),np.array(D[seti][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
