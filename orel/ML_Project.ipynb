{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_helpers\n",
    "import implementations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting dataset\")\n",
    "y_train_ref_source, X_train_ref_source, id1 = proj1_helpers.load_csv_data(\"train.csv\")\n",
    "#y_test_ref, X_test_ref, id2 = proj1_helpers.load_csv_data(\"test.csv\")\n",
    "\n",
    "X_train_ref, X_test_ref, y_train_ref, y_test_ref = implementations.split_data(X_train_ref_source, y_train_ref_source, 0.90,23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247500, 120)\n",
      "number of features :  120\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([X_train_ref,np.power(X_train_ref,2),np.power(X_train_ref,3),np.power(X_train_ref,4)],axis = 1)\n",
    "y_train = y_train_ref\n",
    "X_test = np.concatenate((X_test_ref,np.power(X_test_ref,2),np.power(X_test_ref,3),np.power(X_test_ref,4)),axis = 1)\n",
    "y_test = y_test_ref\n",
    "print(X_train.shape)\n",
    "\n",
    "num_features = X_train[0].shape[0]\n",
    "print(\"number of features : \", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_ridge(lambda_, degree, batch_size):\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(1,degree+1):\n",
    "        x.append(np.power(X_train_ref,i))\n",
    "        xt.append(np.power(X_test_ref,i))\n",
    "        \n",
    "    X_train = np.concatenate(x,axis = 1)\n",
    "    y_train = y_train_ref\n",
    "    X_test = np.concatenate(xt,axis = 1)\n",
    "    y_test = y_test_ref\n",
    "    \n",
    "    #print(\"X_train shape : \", X_train.shape,\"    X_test.shape : \", X_test.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape,\"    y_test.shape : \", y_test.shape)\n",
    "    \n",
    "    num_features = X_train[0].shape[0]\n",
    "    #print(\"number of features : \", num_features)\n",
    "\n",
    "    #print(\"Splitting dataset into batch\")\n",
    "    X_batch = np.array_split(X_train, 1)\n",
    "    y_batch = np.array_split(y_train, 1)\n",
    "\n",
    "    #print(X_batch[0].shape)\n",
    "    \n",
    "    w = []\n",
    "    i=0\n",
    "    for y,batch in zip(y_batch,X_batch):\n",
    "        w.append(implementations.ridge_regression(y, batch,lambda_))\n",
    "    \n",
    "    \n",
    "    wp =  np.sum(np.array(w),axis=0)/(len(X_batch))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    y_pred_ridge_train = proj1_helpers.predict_labels(wp,X_train)\n",
    "    y_pred_ridge_test = proj1_helpers.predict_labels(wp,X_test)\n",
    "    s_tr = 0\n",
    "    s_te = 0\n",
    "    tot_tr = 0\n",
    "    for i,y in enumerate(y_train):\n",
    "        if y == y_pred_ridge_train[i]:\n",
    "            s_tr += 1\n",
    "        tot_tr += 1\n",
    "    tot_te = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y == y_pred_ridge_test[i]:\n",
    "            s_te += 1\n",
    "        tot_te += 1\n",
    "\n",
    "    print(\"Ridge precision on train : \",s_tr/tot_tr,\"     Ridge precision on test : \",s_te/tot_te)\n",
    "    \n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge precision on train :  0.7995288888888888      Ridge precision on test :  0.79984\n",
      "Ridge precision on train :  0.7995688888888889      Ridge precision on test :  0.79976\n",
      "Ridge precision on train :  0.7995866666666667      Ridge precision on test :  0.79968\n",
      "coucou\n"
     ]
    }
   ],
   "source": [
    "batch_ridge(400,6,32)\n",
    "batch_ridge(500,6,32)\n",
    "batch_ridge(600,6,32)\n",
    "print(\"coucou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_lasso(lambda_, degree, batch_size):\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(1,degree+1):\n",
    "        x.append(np.power(X_train_ref,i))\n",
    "        xt.append(np.power(X_test_ref,i))\n",
    "        \n",
    "    X_train = np.concatenate(x,axis = 1)\n",
    "    y_train = y_train_ref\n",
    "    X_test = np.concatenate(xt,axis = 1)\n",
    "    y_test = y_test_ref\n",
    "    \n",
    "    #print(\"X_train shape : \", X_train.shape,\"    X_test.shape : \", X_test.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape,\"    y_test.shape : \", y_test.shape)\n",
    "    \n",
    "    num_features = X_train[0].shape[0]\n",
    "    #print(\"number of features : \", num_features)\n",
    "\n",
    "    #print(\"Splitting dataset into batch\")\n",
    "    X_batch = np.array_split(X_train, 1)\n",
    "    y_batch = np.array_split(y_train, 1)\n",
    "\n",
    "    #print(X_batch[0].shape)\n",
    "    \n",
    "    w = []\n",
    "    i=0\n",
    "    w0 = np.random.rand(num_features)\n",
    "    print(w0)\n",
    "    for y,batch in zip(y_batch,X_batch):\n",
    "        w.append(implementations.stochastic_gradient_descent_lasso(y, batch, w0, batch_size,50,-1.000e-20, lambda_))\n",
    "    \n",
    "    print(w)\n",
    "    wp = np.sum(np.array(w),axis=0)/(len(X_batch))\n",
    "    \n",
    "\n",
    "    y_pred_ridge_train = proj1_helpers.predict_labels(wp,X_train)\n",
    "    y_pred_ridge_test = proj1_helpers.predict_labels(wp,X_test)\n",
    "    s_tr = 0\n",
    "    s_te = 0\n",
    "    tot_tr = 0\n",
    "    for i,y in enumerate(y_train):\n",
    "        if y == y_pred_ridge_train[i]:\n",
    "            s_tr += 1\n",
    "        tot_tr += 1\n",
    "    tot_te = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y == y_pred_ridge_test[i]:\n",
    "            s_te += 1\n",
    "        tot_te += 1\n",
    "\n",
    "    print(\"Lasso precision on train : \",s_tr/tot_tr,\"     Lasso precision on test : \",s_te/tot_te)\n",
    "    \n",
    "    return wp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "reg = LogisticRegressionCV(cv=5, random_state=0, max_iter=100).fit(X_train_ref_source, y_train_ref_source)\n",
    "print(reg.score(X_train_ref_source, y_train_ref_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50850538  0.59667111  0.24626263  0.45061735  0.85724532  0.52767464\n",
      "  0.28761998  0.73318231  0.44932648  0.29953913  0.09587732  0.29751878\n",
      "  0.69221698  0.51547789  0.89357282  0.57585264  0.35371031  0.55325153\n",
      "  0.25576939  0.0276545   0.98550748  0.73004497  0.67554279  0.81018544\n",
      "  0.21288865  0.04588872  0.16002938  0.78491277  0.25547073  0.75120951\n",
      "  0.6279533   0.32927656  0.4332087   0.8580835   0.29962124  0.11854872\n",
      "  0.27583123  0.14726201  0.53643789  0.72152782  0.45472037  0.41916335\n",
      "  0.90550033  0.55197373  0.96643395  0.28880636  0.29987826  0.19471445\n",
      "  0.76044856  0.54284701  0.02165509  0.00547249  0.97619346  0.08661256\n",
      "  0.55053008  0.27978653  0.69038956  0.64396738  0.13199886  0.8535361\n",
      "  0.58605596  0.08023227  0.57153055  0.1209062   0.90005204  0.4257553\n",
      "  0.63344603  0.84093498  0.33205407  0.89301794  0.00161895  0.5064487\n",
      "  0.45215881  0.96224021  0.72326423  0.35164921  0.49539207  0.86757243\n",
      "  0.27740527  0.79940789  0.64527297  0.8016363   0.20378307  0.65357916\n",
      "  0.8143382   0.55843632  0.76760068  0.56084862  0.06932521  0.71600827]\n",
      "[array([  5.08506518e-01,   5.96670573e-01,   2.46261824e-01,\n",
      "         4.50617050e-01,   8.57255296e-01,   5.27684956e-01,\n",
      "         2.87629958e-01,   7.33182289e-01,   4.49326340e-01,\n",
      "         2.99538170e-01,   9.58773065e-02,   2.97518789e-01,\n",
      "         6.92226957e-01,   5.15477549e-01,   8.93572822e-01,\n",
      "         5.75852640e-01,   3.53709879e-01,   5.53251529e-01,\n",
      "         2.55769385e-01,   2.76541684e-02,   9.85507480e-01,\n",
      "         7.30043505e-01,   6.75542785e-01,   8.10191540e-01,\n",
      "         2.12894957e-01,   4.58950299e-02,   1.60039371e-01,\n",
      "         7.84922749e-01,   2.55480706e-01,   7.51209317e-01,\n",
      "         6.25744502e-01,   3.29236174e-01,   4.33126884e-01,\n",
      "         8.58064115e-01,   2.89656091e-01,   1.09262085e-01,\n",
      "         2.65866090e-01,   1.47261945e-01,   5.36433977e-01,\n",
      "         7.21421031e-01,   4.54720345e-01,   4.19163330e-01,\n",
      "         8.95535174e-01,   5.51959009e-01,   9.66433933e-01,\n",
      "         2.88806327e-01,   2.99856872e-01,   1.94714431e-01,\n",
      "         7.60448526e-01,   5.42832006e-01,   2.16550571e-02,\n",
      "         5.21456595e-03,   9.76193459e-01,   8.02972825e-02,\n",
      "         5.44230937e-01,   2.73487386e-01,   6.80425871e-01,\n",
      "         6.34002231e-01,   1.22033703e-01,   8.53529370e-01,\n",
      "         2.62533664e+00,   7.65320256e-02,   5.60415746e-01,\n",
      "         1.19427314e-01,   1.08552424e+01,   1.19657508e+01,\n",
      "         1.05886361e+01,   8.40934778e-01,   3.32523744e-01,\n",
      "         8.83534824e-01,   1.61890050e-03,   5.06448709e-01,\n",
      "         1.04073491e+01,   9.61430221e-01,   7.23264227e-01,\n",
      "         3.51649212e-01,   4.94117158e-01,   8.67572433e-01,\n",
      "         2.77405272e-01,   7.99101700e-01,   6.45272967e-01,\n",
      "         7.52446659e-01,   2.03783068e-01,   6.94471310e+00,\n",
      "         7.10717391e+00,   6.85127203e+00,   1.07230009e+01,\n",
      "         1.05160389e+01,   1.00245155e+01,   7.19601117e-01])]\n",
      "Lasso precision on train :  0.6394711111111111      Lasso precision on test :  0.64544\n",
      "coucou\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_lasso(0,3,1024)\n",
    "print(\"coucou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3966a05133d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_GD_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproj1_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_ridge_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wg' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_GD_train = proj1_helpers.predict_labels(wg,X_train)\n",
    "s = 0\n",
    "tot = 0\n",
    "for i,y in enumerate(y_pred_ridge_train):\n",
    "    if y == y_train[i]:\n",
    "        s += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"GD precision on train : \",s/tot)\n",
    "\n",
    "y_pred_GD_test = proj1_helpers.predict_labels(wg,X_test)\n",
    "s = 0\n",
    "tot = 0\n",
    "for i,y in enumerate(y_pred_ridge_test):\n",
    "    if y == y_test[i]:\n",
    "        s += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"GD precision on test : \",s/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest, input_data_test, ids_test = proj1_helpers.load_csv_data(\"test.csv\")\n",
    "xsub = []\n",
    "degree = 6\n",
    "for i in range(1,degree+1):\n",
    "    xsub.append(np.power(input_data_test,i))\n",
    "        \n",
    "inp = np.concatenate(xsub,axis = 1)\n",
    "ypred = proj1_helpers.predict_labels(w, inp)\n",
    "proj1_helpers.create_csv_submission(ids_test, ypred, \"pred1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
