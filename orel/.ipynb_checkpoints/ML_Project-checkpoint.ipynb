{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_helpers\n",
    "import implementations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting dataset\")\n",
    "y_train_ref_source, X_train_ref_source, id1 = proj1_helpers.load_csv_data(\"../train.csv\")\n",
    "#y_test_ref, X_test_ref, id2 = proj1_helpers.load_csv_data(\"test.csv\")\n",
    "\n",
    "X_train_ref, X_test_ref, y_train_ref, y_test_ref = implementations.split_data(X_train_ref_source, y_train_ref_source, 0.90,23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247500, 120)\n",
      "number of features :  120\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([X_train_ref,np.power(X_train_ref,2),np.power(X_train_ref,3),np.power(X_train_ref,4)],axis = 1)\n",
    "y_train = y_train_ref\n",
    "X_test = np.concatenate((X_test_ref,np.power(X_test_ref,2),np.power(X_test_ref,3),np.power(X_test_ref,4)),axis = 1)\n",
    "y_test = y_test_ref\n",
    "print(X_train.shape)\n",
    "\n",
    "num_features = X_train[0].shape[0]\n",
    "print(\"number of features : \", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_ridge(lambda_, degree, batch_size):\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(1,degree+1):\n",
    "        x.append(np.power(X_train_ref,i))\n",
    "        xt.append(np.power(X_test_ref,i))\n",
    "        \n",
    "    X_train = np.concatenate(x,axis = 1)\n",
    "    y_train = y_train_ref\n",
    "    X_test = np.concatenate(xt,axis = 1)\n",
    "    y_test = y_test_ref\n",
    "    \n",
    "    #print(\"X_train shape : \", X_train.shape,\"    X_test.shape : \", X_test.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape,\"    y_test.shape : \", y_test.shape)\n",
    "    \n",
    "    num_features = X_train[0].shape[0]\n",
    "    #print(\"number of features : \", num_features)\n",
    "\n",
    "    #print(\"Splitting dataset into batch\")\n",
    "    X_batch = np.array_split(X_train, 1)\n",
    "    y_batch = np.array_split(y_train, 1)\n",
    "\n",
    "    #print(X_batch[0].shape)\n",
    "    \n",
    "    w = []\n",
    "    i=0\n",
    "    for y,batch in zip(y_batch,X_batch):\n",
    "        w.append(implementations.ridge_regression(y, batch,lambda_))\n",
    "    \n",
    "    \n",
    "    wp =  np.sum(np.array(w),axis=0)/(len(X_batch))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    y_pred_ridge_train = proj1_helpers.predict_labels(wp,X_train)\n",
    "    y_pred_ridge_test = proj1_helpers.predict_labels(wp,X_test)\n",
    "    s_tr = 0\n",
    "    s_te = 0\n",
    "    tot_tr = 0\n",
    "    for i,y in enumerate(y_train):\n",
    "        if y == y_pred_ridge_train[i]:\n",
    "            s_tr += 1\n",
    "        tot_tr += 1\n",
    "    tot_te = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y == y_pred_ridge_test[i]:\n",
    "            s_te += 1\n",
    "        tot_te += 1\n",
    "\n",
    "    print(\"Ridge precision on train : \",s_tr/tot_tr,\"     Ridge precision on test : \",s_te/tot_te)\n",
    "    \n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge precision on train :  0.7993377777777778      Ridge precision on test :  0.7998\n",
      "Ridge precision on train :  0.7968533333333333      Ridge precision on test :  0.79748\n",
      "Ridge precision on train :  0.7989866666666666      Ridge precision on test :  0.79996\n",
      "Ridge precision on train :  0.7995288888888888      Ridge precision on test :  0.79984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  3.18687815e-02,   4.00602109e-03,   5.81144466e-03,\n",
       "        -3.48540142e-03,  -3.23277203e-02,  -3.22058003e-03,\n",
       "        -4.57277983e-02,  -5.63780417e-02,  -9.04041315e-04,\n",
       "         1.75133934e-02,  -9.59349772e-03,  -9.50598695e-02,\n",
       "        -3.55981737e-02,   3.83804140e-02,  -1.50857324e-03,\n",
       "        -3.29599676e-03,  -2.34206562e-03,   8.43382885e-04,\n",
       "         3.29364413e-03,  -7.95493717e-03,  -1.06744465e-03,\n",
       "         2.97954985e-03,  -3.01230182e-02,   1.59118725e-02,\n",
       "         6.33941839e-03,  -6.99361603e-03,   3.68129661e-03,\n",
       "         1.25789656e-02,  -2.71499212e-03,  -1.86036404e-02,\n",
       "        -1.59171981e-04,  -3.16174100e-04,  -1.23821104e-04,\n",
       "         4.17287268e-05,  -1.41743658e-03,   7.26768199e-06,\n",
       "        -9.99860175e-04,   5.43661726e-02,  -1.83005223e-05,\n",
       "         2.96745159e-05,   7.52821442e-02,   1.39905000e-02,\n",
       "         3.55587729e-01,  -7.67133382e-04,  -5.08630648e-03,\n",
       "        -8.19594608e-04,  -4.39944019e-04,  -3.28372360e-02,\n",
       "         1.78369008e-03,   2.20360332e-04,  -2.71341467e-03,\n",
       "        -1.28774512e-05,  -5.53508338e-02,  -1.75824943e-04,\n",
       "         3.98924522e-02,   1.22704949e-04,   6.12355147e-05,\n",
       "         3.67715904e-02,  -1.77465389e-03,  -3.55993325e-05,\n",
       "         2.58730270e-07,   3.20882799e-06,   5.70157879e-07,\n",
       "        -2.64389276e-07,  -1.13051889e-04,  -6.84876826e-09,\n",
       "        -6.79153554e-05,   1.02420058e-01,   5.99730852e-07,\n",
       "        -6.63609741e-08,  -1.60778315e-02,   1.68001038e-01,\n",
       "         1.84547908e-03,   4.68609931e-06,   1.48764896e-04,\n",
       "         9.52802765e-04,   3.96244701e-06,   3.92486357e-04,\n",
       "        -4.87772172e-04,  -1.75063176e-06,   3.96832702e-04,\n",
       "         1.97467119e-08,  -9.60090404e-02,   9.62492176e-07,\n",
       "        -9.56678430e-04,   1.10904121e-03,  -8.02511833e-07,\n",
       "        -1.33000770e-03,   3.25125607e-04,   9.01047638e-08,\n",
       "        -1.55209876e-11,  -1.22411122e-08,  -1.05724059e-09,\n",
       "         7.71309383e-10,   1.78323746e-06,   3.00372681e-12,\n",
       "        -3.13298225e-06,  -7.28567880e-02,  -3.57596460e-09,\n",
       "         8.23920507e-11,   1.34601335e-03,   1.28613302e-02,\n",
       "         4.84902150e-06,  -1.44987080e-08,  -6.86689544e-03,\n",
       "        -1.55055566e-04,  -1.71754563e-08,  -2.42000957e-03,\n",
       "        -6.34022144e-04,   6.20313263e-09,   1.04201119e-03,\n",
       "        -1.45726079e-11,  -1.47946018e-01,  -2.65727058e-09,\n",
       "        -3.91818948e-07,  -4.80301302e-07,   3.30977127e-09,\n",
       "        -8.96969493e-07,  -1.88901658e-06,  -1.23091129e-10,\n",
       "        -2.90796549e-13,   1.97147285e-11,   8.46226809e-13,\n",
       "        -1.03174559e-12,  -8.68280507e-10,  -6.09604642e-16,\n",
       "        -9.15989708e-09,   1.65389910e-02,   7.64255707e-12,\n",
       "        -4.95801145e-14,  -4.99079091e-05,  -4.69080735e-02,\n",
       "         1.10024636e-09,   2.14502180e-11,  -3.06190476e-06,\n",
       "        -6.15602519e-05,   3.50669280e-11,  -2.11460097e-04,\n",
       "        -1.20997026e-05,  -9.80712565e-12,  -2.81558695e-05,\n",
       "         5.45427431e-15,  -1.63674731e-01,   3.51844756e-12,\n",
       "         6.52352839e-09,  -5.80125876e-09,  -5.64699607e-12,\n",
       "         1.34193167e-09,   6.33339668e-09,   8.16873799e-14,\n",
       "         1.77445906e-16,  -1.12885557e-14,  -2.43218898e-16,\n",
       "         5.10241967e-16,  -3.58168570e-14,   4.59964369e-20,\n",
       "        -2.63501204e-12,  -1.21565464e-03,  -5.40357422e-15,\n",
       "         1.12687519e-17,   6.88749507e-07,  -4.62836982e-03,\n",
       "        -3.23292565e-12,  -1.19725865e-14,   7.31776556e-04,\n",
       "         2.86671874e-05,  -2.70417902e-14,   4.52077979e-04,\n",
       "         5.17375176e-05,   5.60438476e-15,  -8.96356051e-05,\n",
       "        -1.03302423e-18,   6.93633610e-02,  -1.76713175e-15,\n",
       "        -1.08758005e-12,   2.80619411e-12,   3.37684256e-15,\n",
       "         5.32974907e-12,  -1.13601975e-12,  -2.00789143e-17])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ridge(4000,6,32)\n",
    "batch_ridge(40000,6,32)\n",
    "batch_ridge(8000,6,32)\n",
    "batch_ridge(400,6,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_lasso(lambda_, degree, batch_size):\n",
    "    x = []\n",
    "    xt = []\n",
    "    for i in range(1,degree+1):\n",
    "        x.append(np.power(X_train_ref,i))\n",
    "        xt.append(np.power(X_test_ref,i))\n",
    "        \n",
    "    X_train = np.concatenate(x,axis = 1)\n",
    "    y_train = y_train_ref\n",
    "    X_test = np.concatenate(xt,axis = 1)\n",
    "    y_test = y_test_ref\n",
    "    \n",
    "    #print(\"X_train shape : \", X_train.shape,\"    X_test.shape : \", X_test.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape,\"    y_test.shape : \", y_test.shape)\n",
    "    \n",
    "    num_features = X_train[0].shape[0]\n",
    "    #print(\"number of features : \", num_features)\n",
    "\n",
    "    #print(\"Splitting dataset into batch\")\n",
    "    X_batch = np.array_split(X_train, 1)\n",
    "    y_batch = np.array_split(y_train, 1)\n",
    "\n",
    "    #print(X_batch[0].shape)\n",
    "    \n",
    "    w = []\n",
    "    i=0\n",
    "    w0 = np.random.rand(num_features)\n",
    "    print(w0)\n",
    "    for y,batch in zip(y_batch,X_batch):\n",
    "        w.append(implementations.stochastic_gradient_descent_lasso(y, batch, w0, batch_size,50,-1.000e-20, lambda_))\n",
    "    \n",
    "    print(w)\n",
    "    wp = np.sum(np.array(w),axis=0)/(len(X_batch))\n",
    "    \n",
    "\n",
    "    y_pred_ridge_train = proj1_helpers.predict_labels(wp,X_train)\n",
    "    y_pred_ridge_test = proj1_helpers.predict_labels(wp,X_test)\n",
    "    s_tr = 0\n",
    "    s_te = 0\n",
    "    tot_tr = 0\n",
    "    for i,y in enumerate(y_train):\n",
    "        if y == y_pred_ridge_train[i]:\n",
    "            s_tr += 1\n",
    "        tot_tr += 1\n",
    "    tot_te = 0\n",
    "    for i,y in enumerate(y_test):\n",
    "        if y == y_pred_ridge_test[i]:\n",
    "            s_te += 1\n",
    "        tot_te += 1\n",
    "\n",
    "    print(\"Lasso precision on train : \",s_tr/tot_tr,\"     Lasso precision on test : \",s_te/tot_te)\n",
    "    \n",
    "    return wp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "reg = LogisticRegressionCV(cv=5, random_state=0, max_iter=100).fit(X_train_ref_source, y_train_ref_source)\n",
    "print(reg.score(X_train_ref_source, y_train_ref_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50850538  0.59667111  0.24626263  0.45061735  0.85724532  0.52767464\n",
      "  0.28761998  0.73318231  0.44932648  0.29953913  0.09587732  0.29751878\n",
      "  0.69221698  0.51547789  0.89357282  0.57585264  0.35371031  0.55325153\n",
      "  0.25576939  0.0276545   0.98550748  0.73004497  0.67554279  0.81018544\n",
      "  0.21288865  0.04588872  0.16002938  0.78491277  0.25547073  0.75120951\n",
      "  0.6279533   0.32927656  0.4332087   0.8580835   0.29962124  0.11854872\n",
      "  0.27583123  0.14726201  0.53643789  0.72152782  0.45472037  0.41916335\n",
      "  0.90550033  0.55197373  0.96643395  0.28880636  0.29987826  0.19471445\n",
      "  0.76044856  0.54284701  0.02165509  0.00547249  0.97619346  0.08661256\n",
      "  0.55053008  0.27978653  0.69038956  0.64396738  0.13199886  0.8535361\n",
      "  0.58605596  0.08023227  0.57153055  0.1209062   0.90005204  0.4257553\n",
      "  0.63344603  0.84093498  0.33205407  0.89301794  0.00161895  0.5064487\n",
      "  0.45215881  0.96224021  0.72326423  0.35164921  0.49539207  0.86757243\n",
      "  0.27740527  0.79940789  0.64527297  0.8016363   0.20378307  0.65357916\n",
      "  0.8143382   0.55843632  0.76760068  0.56084862  0.06932521  0.71600827]\n",
      "[array([  5.08506518e-01,   5.96670573e-01,   2.46261824e-01,\n",
      "         4.50617050e-01,   8.57255296e-01,   5.27684956e-01,\n",
      "         2.87629958e-01,   7.33182289e-01,   4.49326340e-01,\n",
      "         2.99538170e-01,   9.58773065e-02,   2.97518789e-01,\n",
      "         6.92226957e-01,   5.15477549e-01,   8.93572822e-01,\n",
      "         5.75852640e-01,   3.53709879e-01,   5.53251529e-01,\n",
      "         2.55769385e-01,   2.76541684e-02,   9.85507480e-01,\n",
      "         7.30043505e-01,   6.75542785e-01,   8.10191540e-01,\n",
      "         2.12894957e-01,   4.58950299e-02,   1.60039371e-01,\n",
      "         7.84922749e-01,   2.55480706e-01,   7.51209317e-01,\n",
      "         6.25744502e-01,   3.29236174e-01,   4.33126884e-01,\n",
      "         8.58064115e-01,   2.89656091e-01,   1.09262085e-01,\n",
      "         2.65866090e-01,   1.47261945e-01,   5.36433977e-01,\n",
      "         7.21421031e-01,   4.54720345e-01,   4.19163330e-01,\n",
      "         8.95535174e-01,   5.51959009e-01,   9.66433933e-01,\n",
      "         2.88806327e-01,   2.99856872e-01,   1.94714431e-01,\n",
      "         7.60448526e-01,   5.42832006e-01,   2.16550571e-02,\n",
      "         5.21456595e-03,   9.76193459e-01,   8.02972825e-02,\n",
      "         5.44230937e-01,   2.73487386e-01,   6.80425871e-01,\n",
      "         6.34002231e-01,   1.22033703e-01,   8.53529370e-01,\n",
      "         2.62533664e+00,   7.65320256e-02,   5.60415746e-01,\n",
      "         1.19427314e-01,   1.08552424e+01,   1.19657508e+01,\n",
      "         1.05886361e+01,   8.40934778e-01,   3.32523744e-01,\n",
      "         8.83534824e-01,   1.61890050e-03,   5.06448709e-01,\n",
      "         1.04073491e+01,   9.61430221e-01,   7.23264227e-01,\n",
      "         3.51649212e-01,   4.94117158e-01,   8.67572433e-01,\n",
      "         2.77405272e-01,   7.99101700e-01,   6.45272967e-01,\n",
      "         7.52446659e-01,   2.03783068e-01,   6.94471310e+00,\n",
      "         7.10717391e+00,   6.85127203e+00,   1.07230009e+01,\n",
      "         1.05160389e+01,   1.00245155e+01,   7.19601117e-01])]\n",
      "Lasso precision on train :  0.6394711111111111      Lasso precision on test :  0.64544\n",
      "coucou\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_lasso(0,3,1024)\n",
    "print(\"coucou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3966a05133d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_GD_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproj1_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_ridge_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wg' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_GD_train = proj1_helpers.predict_labels(wg,X_train)\n",
    "s = 0\n",
    "tot = 0\n",
    "for i,y in enumerate(y_pred_ridge_train):\n",
    "    if y == y_train[i]:\n",
    "        s += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"GD precision on train : \",s/tot)\n",
    "\n",
    "y_pred_GD_test = proj1_helpers.predict_labels(wg,X_test)\n",
    "s = 0\n",
    "tot = 0\n",
    "for i,y in enumerate(y_pred_ridge_test):\n",
    "    if y == y_test[i]:\n",
    "        s += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"GD precision on test : \",s/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest, input_data_test, ids_test = proj1_helpers.load_csv_data(\"test.csv\")\n",
    "xsub = []\n",
    "degree = 6\n",
    "for i in range(1,degree+1):\n",
    "    xsub.append(np.power(input_data_test,i))\n",
    "        \n",
    "inp = np.concatenate(xsub,axis = 1)\n",
    "ypred = proj1_helpers.predict_labels(w, inp)\n",
    "proj1_helpers.create_csv_submission(ids_test, ypred, \"pred1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
